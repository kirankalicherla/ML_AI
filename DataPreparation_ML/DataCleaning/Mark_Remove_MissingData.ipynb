{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "downtown-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tutorial Overview\n",
    "##1.Diabetes Dataset\n",
    "##1.Mark missing values\n",
    "##2.Missing values causes problems\n",
    "##3.Remove rows missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-scholarship",
   "metadata": {},
   "source": [
    "### Mark Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "growing-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1           2           3           4           5  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
      "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
      "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "                6           7           8  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.471876   33.240885    0.348958  \n",
      "std      0.331329   11.760232    0.476951  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243750   24.000000    0.000000  \n",
      "50%      0.372500   29.000000    0.000000  \n",
      "75%      0.626250   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "## We can use plots and summary statistics to help identify the missing or corrupt data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Load the dataset\n",
    "dataset = pd.read_csv('pima-indians-diabetes.csv',header = None)\n",
    "\n",
    "#Summarize the dataset\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "christian-springer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1   2   3    4     5      6   7  8\n",
      "0    6  148  72  35    0  33.6  0.627  50  1\n",
      "1    1   85  66  29    0  26.6  0.351  31  0\n",
      "2    8  183  64   0    0  23.3  0.672  32  1\n",
      "3    1   89  66  23   94  28.1  0.167  21  0\n",
      "4    0  137  40  35  168  43.1  2.288  33  1\n",
      "5    5  116  74   0    0  25.6  0.201  30  0\n",
      "6    3   78  50  32   88  31.0  0.248  26  1\n",
      "7   10  115   0   0    0  35.3  0.134  29  0\n",
      "8    2  197  70  45  543  30.5  0.158  53  1\n",
      "9    8  125  96   0    0   0.0  0.232  54  1\n",
      "10   4  110  92   0    0  37.6  0.191  30  0\n",
      "11  10  168  74   0    0  38.0  0.537  34  1\n",
      "12  10  139  80   0    0  27.1  1.441  57  0\n",
      "13   1  189  60  23  846  30.1  0.398  59  1\n",
      "14   5  166  72  19  175  25.8  0.587  51  1\n",
      "15   7  100   0   0    0  30.0  0.484  32  1\n",
      "16   0  118  84  47  230  45.8  0.551  31  1\n",
      "17   7  107  74   0    0  29.6  0.254  31  1\n",
      "18   1  103  30  38   83  43.3  0.183  33  0\n",
      "19   1  115  70  30   96  34.6  0.529  32  1\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "temporal-passenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Count the number of missing values for each column\n",
    "num_missing = (dataset[[1,2,3,4,5]] == 0).sum()\n",
    "\n",
    "# report the result\n",
    "print(num_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "considerable-major",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## replace 0 values with nan\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0,np.nan)\n",
    "\n",
    "# count the number of nan values in each column\n",
    "\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fluid-momentum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0      1     2     3      4     5      6   7  8\n",
      "0    6  148.0  72.0  35.0    NaN  33.6  0.627  50  1\n",
      "1    1   85.0  66.0  29.0    NaN  26.6  0.351  31  0\n",
      "2    8  183.0  64.0   NaN    NaN  23.3  0.672  32  1\n",
      "3    1   89.0  66.0  23.0   94.0  28.1  0.167  21  0\n",
      "4    0  137.0  40.0  35.0  168.0  43.1  2.288  33  1\n",
      "5    5  116.0  74.0   NaN    NaN  25.6  0.201  30  0\n",
      "6    3   78.0  50.0  32.0   88.0  31.0  0.248  26  1\n",
      "7   10  115.0   NaN   NaN    NaN  35.3  0.134  29  0\n",
      "8    2  197.0  70.0  45.0  543.0  30.5  0.158  53  1\n",
      "9    8  125.0  96.0   NaN    NaN   NaN  0.232  54  1\n",
      "10   4  110.0  92.0   NaN    NaN  37.6  0.191  30  0\n",
      "11  10  168.0  74.0   NaN    NaN  38.0  0.537  34  1\n",
      "12  10  139.0  80.0   NaN    NaN  27.1  1.441  57  0\n",
      "13   1  189.0  60.0  23.0  846.0  30.1  0.398  59  1\n",
      "14   5  166.0  72.0  19.0  175.0  25.8  0.587  51  1\n",
      "15   7  100.0   NaN   NaN    NaN  30.0  0.484  32  1\n",
      "16   0  118.0  84.0  47.0  230.0  45.8  0.551  31  1\n",
      "17   7  107.0  74.0   NaN    NaN  29.6  0.254  31  1\n",
      "18   1  103.0  30.0  38.0   83.0  43.3  0.183  33  0\n",
      "19   1  115.0  70.0  30.0   96.0  34.6  0.529  32  1\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-stage",
   "metadata": {},
   "source": [
    "### Missing Values Cause Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incomplete-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 425, in fit\n",
      "    dtype=[np.float64, np.float32])\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 802, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 645, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 99, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 425, in fit\n",
      "    dtype=[np.float64, np.float32])\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 802, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 645, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 99, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 425, in fit\n",
      "    dtype=[np.float64, np.float32])\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 802, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 645, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"D:\\Anaconda_Distribution\\envs\\newEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 99, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "###Example where missing values causes errors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#load the dataset\n",
    "data = pd.read_csv('pima-indians-diabetes.csv',header=None)\n",
    "\n",
    "#replace 0 with nan\n",
    "data[[1,2,3,4,5]]  = data[[1,2,3,4,5]].replace(0,np.nan)\n",
    "\n",
    "#values\n",
    "values = data.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "\n",
    "#Define Model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "#Define the model Evaluation procedure\n",
    "\n",
    "cv = KFold(n_splits=3,shuffle=True,random_state=1)\n",
    "\n",
    "#evaluate the model\n",
    "\n",
    "results = cross_val_score(model,X,y,cv=cv,scoring=\"accuracy\")\n",
    "\n",
    "#report the mean performance\n",
    "print('Accuracy: %.3f'%results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-candle",
   "metadata": {},
   "source": [
    "### Remove rows with Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "overhead-gamma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "### We can pd.dropna() function to remove the missing data samples\n",
    "data = pd.read_csv('pima-indians-diabetes.csv',header=None)\n",
    "\n",
    "data[[1,2,3,4,5]] = data[[1,2,3,4,5]].replace(0,np.nan)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "print(data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "meaningful-convert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :78.058\n"
     ]
    }
   ],
   "source": [
    "#### Now evaluating the model with this data\n",
    "\n",
    "values = data.values\n",
    "X = values[:,:-1]\n",
    "y = values[:,-1]\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "cv = KFold(n_splits=3,shuffle=True,random_state=1)\n",
    "\n",
    "results = cross_val_score(model,X,y,cv=cv,scoring=\"accuracy\")\n",
    "mean = results.mean()*100\n",
    "print(\"Accuracy is :%.3f\"%mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-glenn",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
